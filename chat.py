import os, json, mimetypes, torch
from torchvision import models, transforms
from PIL import Image, UnidentifiedImageError
from openai import AzureOpenAI
from dotenv import load_dotenv
from retriever import retrieve_event_info

load_dotenv()

# GPT í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

# ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
with open("config.json", "r", encoding="utf-8") as f:
    cfg = json.load(f)

num_classes = cfg["num_classes"]
model_path = cfg["model_path"]
class_names = cfg["class_names"]


model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.fc = torch.nn.Linear(model.fc.in_features, num_classes)


model.load_state_dict(torch.load("paju_model_resnet18_finetuned.pth", map_location='cpu'))
model.to('cpu')
model.eval()

mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

SYSTEM_PROMPT = (
    "ë„ˆëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ë¥¼ ì•ˆë‚´í•˜ëŠ” ì „ë¬¸ ì±—ë´‡ì´ì•¼. "
    "êµ¬ì–´ì²´ë‚˜ ê°íƒ„ì‚¬ ì—†ì´, ì•ˆë‚´ë¬¸ í˜•ì‹ì˜ ë¬¸ì–´ì²´ë¡œ ìž‘ì„±í•´."
)

# ì‚¬ìš©ìžë³„ ëŒ€í™” ížˆìŠ¤í† ë¦¬/ìŠ¤íƒ¬í”„ ì €ìž¥ì†Œ
conversation_sessions = {}
user_stamps = {} 

# GPT ëŒ€í™” ê¸°ëŠ¥
def ask_gpt(user_prompt: str, session_id: str):
    if session_id not in conversation_sessions:
        conversation_sessions[session_id] = [{"role": "system", "content": SYSTEM_PROMPT}]

    conversation_sessions[session_id].append({"role": "user", "content": user_prompt})

    res = client.chat.completions.create(
        model=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
        messages=conversation_sessions[session_id]
    )

    answer = res.choices[0].message.content
    conversation_sessions[session_id].append({"role": "assistant", "content": answer})
    return answer



IMG_EXTS = {".jpg", ".jpeg", ".png"}

def is_image_input(x):
    """ìž…ë ¥ì´ ì´ë¯¸ì§€ì¸ì§€ íŒë³„"""
    if isinstance(x, Image.Image):
        return True
    if isinstance(x, str) and os.path.exists(x):
        ext = os.path.splitext(x)[1].lower()
        mime, _ = mimetypes.guess_type(x)
        return (ext in IMG_EXTS) or ((mime or "").startswith("image/"))
    return False

def predict_place(image_path):
    """ì´ë¯¸ì§€ â†’ ê±´ë¬¼ ë¶„ë¥˜"""
    try:
        img = Image.open(image_path).convert("RGB")
    except (FileNotFoundError, UnidentifiedImageError):
        return "ì´ë¯¸ì§€ ë¡œë“œë¥¼ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”."
    x = transform(img).unsqueeze(0)
    with torch.no_grad():
        outputs = model(x)
        pred_idx = outputs.argmax(dim=1).item()
    return class_names[pred_idx]


# í–‰ì‚¬ RAG 
def text_mode(user_text: str, session_id: str) -> str:
    if any(k in user_text for k in ["í–‰ì‚¬", "ì´ë²¤íŠ¸"]):
        results = retrieve_event_info(user_text, top_k=2)
        if results:
            context = "\n\n".join([r.page_content for r in results])
            prompt = f"""
ì‚¬ìš©ìžê°€ '{user_text}'ë¼ê³  ë¬¼ì—ˆì–´.
ì•„ëž˜ëŠ” ê´€ë ¨ í–‰ì‚¬ ì •ë³´ì•¼:
{context}

ì œëª©, ì¼ì‹œ, ìž¥ì†Œ, ì£¼ìµœ, ìš”ì•½, ì‹ ì²­ë°©ë²•ì„ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ì¤˜.
ê¼­ ì‚¬ìš©ìžê°€ ë³´ê¸° ê¹”ë”í•˜ê²Œ ì¶œë ¥í•´ì¤˜
"""
            return ask_gpt(prompt, session_id)
        else:
            return "í˜„ìž¬ í•´ë‹¹ ì£¼ì œì˜ í–‰ì‚¬ ì •ë³´ëŠ” ì—†ìŠµë‹ˆë‹¤."
    else:
        prompt = f"""
ì‚¬ìš©ìžê°€ '{user_text}'ë¼ê³  ë¬¼ì—ˆì–´.
íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ì´ë©´ 2~3ì¤„ ìš”ì•½ í›„,
'ë‹¤ë¥¸ ì •ë³´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.'ë¼ê³  ìœ ë„ ì§ˆë¬¸ì„ ì¶”ê°€í•˜ë©´ì„œ ë§ˆë¬´ë¦¬.
ì•„ë‹ˆë©´ 'ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì •ë³´ë§Œ ì•ˆë‚´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ì¶œë ¥.
"""
        return ask_gpt(prompt, session_id)


# ì´ë¯¸ì§€ ëª¨ë“œ
def image_mode(image_path: str, session_id: str):
    place_name = predict_place(image_path)
    print(f"\n[ì˜ˆì¸¡ëœ ìž¥ì†Œ] {place_name}")
    print("ì›í•˜ì‹œëŠ” ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ìŠ¤íƒ¬í”„ ì ë¦½")
    print("2. ìž¥ì†Œ ì„¤ëª… ë³´ê¸°")

    choice = input("ë²ˆí˜¸ ìž…ë ¥ >> ").strip()

    # ìŠ¤íƒ¬í”„ ì ë¦½
    if choice == "1":
        if session_id not in user_stamps:
            user_stamps[session_id] = []

        if place_name not in user_stamps[session_id]:
            user_stamps[session_id].append(place_name)
            message = f"'{place_name}'ì˜ ìŠ¤íƒ¬í”„ê°€ ì ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤! ðŸŽ‰"
        else:
            message = f"'{place_name}'ì€(ëŠ”) ì´ë¯¸ ì ë¦½ëœ ìž¥ì†Œìž…ë‹ˆë‹¤. ðŸ˜‰"

        return {"answer": message, "label": place_name}

    # ìž¥ì†Œ ì„¤ëª…
    elif choice == "2":
        prompt = f"""
ì‚¬ìš©ìžê°€ '{place_name}' ì‚¬ì§„ì„ ë³´ëƒˆì–´.
'{place_name}'ì´ íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ì´ë©´ 2~3ì¤„ë¡œ ìš”ì•½í•˜ê³ ,
'ë‹¤ë¥¸ ì •ë³´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.'ë¼ê³  ìœ ë„ ì§ˆë¬¸ì„ ì¶”ê°€í•˜ë©´ì„œ ë§ˆë¬´ë¦¬.
ì•„ë‹ˆë©´ 'ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì •ë³´ë§Œ ì•ˆë‚´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ì¶œë ¥.
"""
        answer = ask_gpt(prompt, session_id)
        return {"answer": answer, "label": place_name}

    # ìž˜ëª»ëœ ìž…ë ¥ ì²˜ë¦¬
    else:
        return {"answer": "ìž˜ëª»ëœ ìž…ë ¥ìž…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", "label": place_name}



def infer_chat(x, session_id: str):
    """
    x: í…ìŠ¤íŠ¸(str) or ì´ë¯¸ì§€ ê²½ë¡œ(str) or PIL.Image
    session_id: ì‚¬ìš©ìžë³„ ê³ ìœ  ID (ì˜ˆ: user_id, ì±„íŒ…ë°© id ë“±)
    """
    if is_image_input(x):
        return image_mode(x, session_id)
    else:
        return {"answer": text_mode(str(x), session_id), "label": None}


# ì¸ì‚¿ë§ í•¨ìˆ˜
def get_greeting():
    """ì•± ì²« ì‹¤í–‰ ì‹œ ë³´ì—¬ì¤„ ì¸ì‚¿ë§"""
    greeting = (
        "ì•ˆë…•í•˜ì„¸ìš”, íŒŒì£¼ ì¶œíŒë‹¨ì§€ ì±—ë´‡ íŒŒëž‘ì´ìž…ë‹ˆë‹¤.\n"
        "í…ìŠ¤íŠ¸ ìž…ë ¥ì´ë‚˜ ì´ë¯¸ì§€ ì—…ë¡œë“œë¥¼ í†µí•´ ì›í•˜ì‹œëŠ” ìž¥ì†Œì˜ ì •ë³´ë¥¼ ì•ˆë‚´ë°›ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
        "ë˜í•œ ì¶œíŒë‹¨ì§€ì—ì„œ ì˜ˆì •ëœ ë‹¤ì–‘í•œ í–‰ì‚¬ ì¼ì •ë„ í•¨ê»˜ í™•ì¸í•˜ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
        "ì‚¬ì§„ì„ ì—…ë¡œë“œë¥¼ í†µí•´ ìŠ¤íƒ¬í”„ë¥¼ ì ë¦½í•  ìˆ˜ë„ ìžˆì–´ìš”!"
    )
    return greeting


if __name__ == "__main__":
    print(get_greeting(), "\n")
    session = "user_001"
    while True:
        sample = input("ìž…ë ¥ (quit ìž…ë ¥ ì‹œ ì¢…ë£Œ) >> ").strip()
        if sample.lower() == "quit":
            break
        result = infer_chat(sample, session)
        print(f"\n{result['answer']}\n")
