import os, json
import torch
from torchvision import models, transforms
from PIL import Image
from openai import AzureOpenAI
from dotenv import load_dotenv
from retriever import retrieve_event_info  


load_dotenv()

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

# ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
with open("config.json", "r", encoding="utf-8") as f:
    cfg = json.load(f)

num_classes = cfg["num_classes"]
model_path = cfg["model_path"]
class_names = cfg["class_names"]

model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
model.load_state_dict(torch.load(model_path, map_location='cpu'))
model.eval()

# ì •ê·œí™”
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

def predict_place(image_path):
    """ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì˜ˆì¸¡"""
    img = Image.open(image_path).convert("RGB")
    input_tensor = transform(img).unsqueeze(0)
    with torch.no_grad():
        outputs = model(input_tensor)
        pred_idx = outputs.argmax(dim=1).item()
    return class_names[pred_idx]

# GPT ëŒ€í™” ê¸°ëŠ¥
conversation_history = [
    {"role": "system", "content": "ë„ˆëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ë¥¼ ì•ˆë‚´í•˜ëŠ” ì „ë¬¸ ì±—ë´‡ì´ì•¼. êµ¬ì–´ì²´ë‚˜ ê°íƒ„ì‚¬ ì—†ì´, ì•ˆë‚´ë¬¸ í˜•ì‹ì˜ ë¬¸ì–´ì²´ë¡œ ì‘ì„±í•´"}
]

def ask_gpt(prompt):
    conversation_history.append({"role": "user", "content": prompt})
    response = client.chat.completions.create(
        model=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
        messages=conversation_history
    )
    answer = response.choices[0].message.content
    conversation_history.append({"role": "assistant", "content": answer})
    return answer


# í…ìŠ¤íŠ¸ ëª¨ë“œ (í–‰ì‚¬ RAG ì—°ë™)
def text_mode():
    while True:
        user_input = input("ì‚¬ìš©ì: ").strip()
        if user_input.lower() == "quit":
            print("ì±—ë´‡: ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.")
            break

        # 'í–‰ì‚¬' ë˜ëŠ” 'ì´ë²¤íŠ¸' í‚¤ì›Œë“œê°€ ë“¤ì–´ê°€ë©´ RAG ê²€ìƒ‰
        if any(keyword in user_input for keyword in ["í–‰ì‚¬", "ì´ë²¤íŠ¸"]):
            results = retrieve_event_info(user_input, top_k=2)
            if results:
                context = "\n\n".join([r.page_content for r in results])
                prompt = f"""
                ì‚¬ìš©ìê°€ '{user_input}'ë¼ê³  ë¬¼ì—ˆì–´.
                ì•„ë˜ëŠ” ê´€ë ¨ëœ í–‰ì‚¬ ì •ë³´ì•¼:
                {context}

                ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— êµ¬ì²´ì ì´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´.
                ì œëª©, ì¼ì‹œ, ì¥ì†Œ, í˜¸ìŠ¤íŠ¸, í•µì‹¬ ìš”ì•½, ì‹ ì²­ë°©ë²• ë° ì‹ ì²­ ë§í¬ ìœ„ì£¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•˜ê³ ,
                ë¶ˆí•„ìš”í•œ ë¬¸ì¥ì€ ìƒëµí•´.
                """
                answer = ask_gpt(prompt)
                print(f"\nğŸ“… í–‰ì‚¬ ì •ë³´\n{answer}\n")
                continue
            else:
                print("ì±—ë´‡: í˜„ì¬ í•´ë‹¹ ì£¼ì œì˜ í–‰ì‚¬ ì •ë³´ëŠ” ì—†ìŠµë‹ˆë‹¤.\n")
                continue

        # í–‰ì‚¬ ì™¸ ì§ˆë¬¸
        prompt = f"""
        ì‚¬ìš©ìê°€ '{user_input}'ë¼ê³  ë¬¼ì—ˆì–´.

        1. íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì§ˆë¬¸ì´ë©´:
           - ì¥ì†Œì˜ í•µì‹¬ ìš”ì•½ë§Œ 2~3ì¤„ë¡œ ì•Œë ¤ì¤˜.
           - ë§ˆì§€ë§‰ì— 'ë‹¤ë¥¸ ì •ë³´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”'ë¼ê³  ìœ ë„ ì§ˆë¬¸ì„ ë§ë¶™ì—¬.

        2. ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì´ë©´:
           - "ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì •ë³´ë§Œ ì•ˆë‚´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤." ë¼ê³ ë§Œ ì¶œë ¥.
        """
        answer = ask_gpt(prompt)
        print(f"\nì±—ë´‡: {answer}\n")

        # ì¶”ê°€ ëŒ€í™” ìœ ë„
        follow_up = input("ì‚¬ìš©ì: ").strip().lower()
        if follow_up in ["ì‘", "ì¢‹ì•„ìš”", "ã…‡ã…‹", "ë” ì•Œë ¤ì¤˜", "ê·¸ë˜"]:
            detail_prompt = f"'{user_input}'ì— ëŒ€í•´ ìì„¸íˆ ì•ˆë‚´ë¬¸ í˜•ì‹ìœ¼ë¡œ ì¨ì¤˜."
            detail_answer = ask_gpt(detail_prompt)
            print(f"\nì±—ë´‡: {detail_answer}\n")
        elif follow_up in ["ì•„ë‹ˆ", "ê´œì°®ì•„ìš”", "ê·¸ë§Œ"]:
            print("ì±—ë´‡: ì•Œê² ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¥ì†Œë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆë‚˜ìš”?\n")
        else:
            next_answer = ask_gpt(f"ì‚¬ìš©ìê°€ '{follow_up}'ë¼ê³  ëŒ€ë‹µí–ˆì–´. ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì¤˜.")
            print(f"\nì±—ë´‡: {next_answer}\n")


# ì´ë¯¸ì§€ ëª¨ë“œ
def image_mode():
    while True:
        image_path = input("ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì…ë ¥ (ì¢…ë£Œí•˜ë ¤ë©´ quit): ").strip()
        if image_path.lower() == "quit":
            print("ì±—ë´‡: ì´ë¯¸ì§€ ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not os.path.exists(image_path):
            print("âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
            continue

        place_name = predict_place(image_path)
        print(f"\n[ëª¨ë¸ ì˜ˆì¸¡ ì¥ì†Œ] {place_name}\n")

        prompt = f"""
        ì‚¬ìš©ìê°€ '{place_name}' ì‚¬ì§„ì„ ë³´ëƒˆì–´.
        ì´ ì¥ì†Œê°€ íŒŒì£¼ ì¶œíŒë‹¨ì§€ì™€ ê´€ë ¨ì´ ìˆë‹¤ë©´:
        - '{place_name}'ì˜ í•µì‹¬ íŠ¹ì§•ì„ 2~3ì¤„ë¡œ ìš”ì•½í•˜ê³ ,
        - ë§ˆì§€ë§‰ì— 'ë‹¤ë¥¸ ì •ë³´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”'ë¼ê³  ìœ ë„ ì§ˆë¬¸ì„ ì¶”ê°€í•´.
        ê´€ë ¨ì´ ì—†ë‹¤ë©´ "ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì •ë³´ë§Œ ì•ˆë‚´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."ë¼ê³ ë§Œ ì¶œë ¥í•´.
        """
        answer = ask_gpt(prompt)
        print(f"\nì±—ë´‡: {answer}\n")

        follow_up = input("ì‚¬ìš©ì: ").strip().lower()
        if follow_up in ["ì‘", "ì¢‹ì•„ìš”", "ã…‡ã…‹", "ë” ì•Œë ¤ì¤˜", "ê·¸ë˜"]:
            detail_prompt = f"'{place_name}'ì— ëŒ€í•´ ìì„¸í•œ ì„¤ëª…(ë¶„ìœ„ê¸°, ë°©ë¬¸ í¬ì¸íŠ¸, ì°¸ê³ ì‚¬í•­)ì„ ì•ˆë‚´ë¬¸ í˜•ì‹ìœ¼ë¡œ ì¨ì¤˜."
            detail_answer = ask_gpt(detail_prompt)
            print(f"\nì±—ë´‡: {detail_answer}\n")
        elif follow_up in ["ì•„ë‹ˆ", "ê´œì°®ì•„ìš”", "ê·¸ë§Œ"]:
            print("ì±—ë´‡: ì•Œê² ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ì§„ì´ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆë‚˜ìš”?\n")
        else:
            next_answer = ask_gpt(f"ì‚¬ìš©ìê°€ '{follow_up}'ë¼ê³  ëŒ€ë‹µí–ˆì–´. ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì¤˜.")
            print(f"\nì±—ë´‡: {next_answer}\n")


def chatbot_interface():
    print("=== íŒŒì£¼ ì¶œíŒë‹¨ì§€ ì•ˆë‚´ ì±—ë´‡ ===")
    print("ì•ˆë…•í•˜ì„¸ìš”, íŒŒì£¼ ì¶œíŒë‹¨ì§€ ì±—ë´‡ì…ë‹ˆë‹¤.")
    print("í…ìŠ¤íŠ¸ ì…ë ¥ì´ë‚˜ ì´ë¯¸ì§€ ì—…ë¡œë“œë¥¼ í†µí•´ ì›í•˜ì‹œëŠ” ì¥ì†Œì˜ ì •ë³´ë¥¼ ì•ˆë‚´ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("ë˜í•œ ì¶œíŒë‹¨ì§€ì—ì„œ ì˜ˆì •ëœ ë‹¤ì–‘í•œ í–‰ì‚¬ ì¼ì •ë„ í•¨ê»˜ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
    print("ì›í•˜ëŠ” ëª¨ë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!\n")

    first_run = True

    while True:
        if first_run:
            print("1. í…ìŠ¤íŠ¸ ì§ˆë¬¸ (í–‰ì‚¬ ê²€ìƒ‰ í¬í•¨)")
            print("2. ì´ë¯¸ì§€ ì—…ë¡œë“œ")
            print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥\n")
            first_run = False

        mode = input(">> ëª¨ë“œ ì„ íƒ (1=text, 2=image): ").strip()
        if mode.lower() == "quit":
            print("ì±—ë´‡: í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        elif mode == "1":
            text_mode()
        elif mode == "2":
            image_mode()
        else:
            print("âš ï¸ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.\n")


if __name__ == "__main__":
    chatbot_interface()
