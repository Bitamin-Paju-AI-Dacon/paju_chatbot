import os, json, mimetypes, torch
from torchvision import models, transforms
from PIL import Image, UnidentifiedImageError
from openai import AzureOpenAI
from dotenv import load_dotenv
from retriever import retrieve_event_info

load_dotenv()

def get_client():
    """ë§¤ ìš”ì²­ë§ˆë‹¤ í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ AzureOpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±"""
    return AzureOpenAI(
        api_key=os.getenv("AZURE_OPENAI_KEY"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION")
    )


# ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
with open("config.json", "r", encoding="utf-8") as f:
    cfg = json.load(f)

num_classes = cfg["num_classes"]
model_path = cfg["model_path"]
class_names = cfg["class_names"]


model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.fc = torch.nn.Linear(model.fc.in_features, num_classes)



mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

SYSTEM_PROMPT = (
    "ë„ˆëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ë¥¼ ì•ˆë‚´í•˜ëŠ” ì „ë¬¸ ì±—ë´‡ì´ì•¼. "
    "êµ¬ì–´ì²´ë‚˜ ê°íƒ„ì‚¬ ì—†ì´, ì•ˆë‚´ë¬¸ í˜•ì‹ì˜ ë¬¸ì–´ì²´ë¡œ ìž‘ì„±í•´."
)

# ì‚¬ìš©ìžë³„ ëŒ€í™” ížˆìŠ¤í† ë¦¬/ìŠ¤íƒ¬í”„ ì €ìž¥ì†Œ
conversation_sessions = {}
user_stamps = {} 

# GPT ëŒ€í™” ê¸°ëŠ¥
def ask_gpt(user_prompt: str, session_id: str):
    client = get_client()
    if session_id not in conversation_sessions:
        conversation_sessions[session_id] = [{"role": "system", "content": SYSTEM_PROMPT}]

    conversation_sessions[session_id].append({"role": "user", "content": user_prompt})

    res = client.chat.completions.create(
        model=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
        messages=conversation_sessions[session_id]
    )

    answer = res.choices[0].message.content
    conversation_sessions[session_id].append({"role": "assistant", "content": answer})
    return answer



IMG_EXTS = {".jpg", ".jpeg", ".png"}

def is_image_input(x):
    """ìž…ë ¥ì´ ì´ë¯¸ì§€ì¸ì§€ íŒë³„"""
    if isinstance(x, Image.Image):
        return True
    if isinstance(x, str) and os.path.exists(x):
        ext = os.path.splitext(x)[1].lower()
        mime, _ = mimetypes.guess_type(x)
        return (ext in IMG_EXTS) or ((mime or "").startswith("image/"))
    return False

def predict_place(image_path):
    """ì´ë¯¸ì§€ â†’ ê±´ë¬¼ ë¶„ë¥˜"""
    try:
        img = Image.open(image_path).convert("RGB")
    except (FileNotFoundError, UnidentifiedImageError):
        return "ì´ë¯¸ì§€ ë¡œë“œë¥¼ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”."
    x = transform(img).unsqueeze(0)
    with torch.no_grad():
        outputs = model(x)
        pred_idx = outputs.argmax(dim=1).item()
    return class_names[pred_idx]


# í–‰ì‚¬ RAG 
def text_mode(user_text: str, session_id: str) -> str:
    if any(k in user_text for k in ["í–‰ì‚¬", "ì´ë²¤íŠ¸"]):
        results = retrieve_event_info(user_text, top_k=2)
        if results:
            context = "\n\n".join([r.page_content for r in results])
            prompt = f"""
ì‚¬ìš©ìžê°€ '{user_text}'ë¼ê³  ë¬¼ì—ˆì–´.
ì•„ëž˜ëŠ” ê´€ë ¨ í–‰ì‚¬ ì •ë³´ì•¼:
{context}

ì œëª©, ì¼ì‹œ, ìž¥ì†Œ, ì£¼ìµœ, ìš”ì•½, ì‹ ì²­ë°©ë²•ì„ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ì¤˜.
ê¼­ ì‚¬ìš©ìžê°€ ë³´ê¸° ê¹”ë”í•˜ê²Œ ì¶œë ¥í•´ì¤˜
"""
            return ask_gpt(prompt, session_id)
        else:
            return "í˜„ìž¬ í•´ë‹¹ ì£¼ì œì˜ í–‰ì‚¬ ì •ë³´ëŠ” ì—†ìŠµë‹ˆë‹¤."
    else:
        prompt = f"""
ì‚¬ìš©ìžê°€ '{user_text}'ë¼ê³  ë¬¼ì—ˆì–´.
íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ì´ë©´ 2~3ì¤„ ìš”ì•½ í›„,
'ë‹¤ë¥¸ ì •ë³´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.'ë¼ê³  ìœ ë„ ì§ˆë¬¸ì„ ì¶”ê°€í•˜ë©´ì„œ ë§ˆë¬´ë¦¬.
ì•„ë‹ˆë©´ 'ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì •ë³´ë§Œ ì•ˆë‚´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ì¶œë ¥.
"""
        return ask_gpt(prompt, session_id)


# ì´ë¯¸ì§€ ëª¨ë“œ
def image_mode(image_path: str, session_id: str, user_text: str = None):
    """
    ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìž¥ì†Œë¥¼ ì˜ˆì¸¡í•˜ê³  ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ
        session_id: ì‚¬ìš©ìž ì„¸ì…˜ ID
        user_text: ì‚¬ìš©ìžê°€ í•¨ê»˜ ìž…ë ¥í•œ í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    """
    place_name = predict_place(image_path)
    
    # ì‚¬ìš©ìžê°€ ìž¥ì†Œ í™•ì¸ì„ ì›í•˜ëŠ” ê²½ìš° (í…ìŠ¤íŠ¸ê°€ ìžˆê±°ë‚˜, ìž¥ì†Œ í™•ì¸ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°)
    place_inquiry_keywords = ["ìž¥ì†Œ", "ì–´ë””", "ë­ì•¼", "ë¬´ì—‡", "ì´ê³³", "ì—¬ê¸°", "ì•Œë ¤", "ì„¤ëª…"]
    wants_stamp = False
    
    if user_text:
        user_text_lower = user_text.lower()
        # ìŠ¤íƒ¬í”„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìžˆìœ¼ë©´ ìŠ¤íƒ¬í”„ ì ë¦½ ì˜ë„ë¡œ íŒë‹¨
        stamp_keywords = ["ìŠ¤íƒ¬í”„", "ì ë¦½", "ì²´í¬ì¸"]
        if any(kw in user_text_lower for kw in stamp_keywords):
            wants_stamp = True
        # ìž¥ì†Œ í™•ì¸ ì˜ë„ê°€ ëª…í™•í•œ ê²½ìš°
        elif any(kw in user_text_lower for kw in place_inquiry_keywords):
            wants_stamp = False
    else:
        # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ìž¥ì†Œ ì„¤ëª… ì œê³µ
        wants_stamp = False
    
    # ìž¥ì†Œ ì„¤ëª… ìƒì„±
    prompt = f"""
ì‚¬ìš©ìžê°€ '{place_name}' ì‚¬ì§„ì„ ë³´ëƒˆì–´.
"""
    if user_text:
        prompt += f"ì‚¬ìš©ìžê°€ '{user_text}'ë¼ê³  ë¬¼ì—ˆì–´.\n"
    
    prompt += f"""
'{place_name}'ì´ íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ì´ë©´ 2~3ì¤„ë¡œ ìš”ì•½í•˜ê³ ,
'ë‹¤ë¥¸ ì •ë³´ì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.'ë¼ê³  ìœ ë„ ì§ˆë¬¸ì„ ì¶”ê°€í•˜ë©´ì„œ ë§ˆë¬´ë¦¬.
ì•„ë‹ˆë©´ 'ì£„ì†¡í•˜ì§€ë§Œ ì €ëŠ” íŒŒì£¼ ì¶œíŒë‹¨ì§€ ê´€ë ¨ ì •ë³´ë§Œ ì•ˆë‚´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ì¶œë ¥.
"""
    answer = ask_gpt(prompt, session_id)
    
    # ìŠ¤íƒ¬í”„ ì ë¦½ ì²˜ë¦¬
    stamp_message = ""
    if wants_stamp:
        if session_id not in user_stamps:
            user_stamps[session_id] = []

        if place_name not in user_stamps[session_id]:
            user_stamps[session_id].append(place_name)
            stamp_message = f"\n\n'{place_name}'ì˜ ìŠ¤íƒ¬í”„ê°€ ì ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤! ðŸŽ‰"
        else:
            stamp_message = f"\n\n'{place_name}'ì€(ëŠ”) ì´ë¯¸ ì ë¦½ëœ ìž¥ì†Œìž…ë‹ˆë‹¤. ðŸ˜‰"
    
    return {"answer": answer + stamp_message, "label": place_name}



def infer_chat(x, session_id: str, user_text: str = None):
    """
    x: í…ìŠ¤íŠ¸(str) or ì´ë¯¸ì§€ ê²½ë¡œ(str) or PIL.Image
    session_id: ì‚¬ìš©ìžë³„ ê³ ìœ  ID (ì˜ˆ: user_id, ì±„íŒ…ë°© id ë“±)
    user_text: ì‚¬ìš©ìžê°€ ìž…ë ¥í•œ í…ìŠ¤íŠ¸ (ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì „ë‹¬ëœ ê²½ìš°)
    """
    if is_image_input(x):
        return image_mode(x, session_id, user_text)
    else:
        # í…ìŠ¤íŠ¸ ìž…ë ¥ì—ì„œ ì´ë¯¸ì§€ ê´€ë ¨ ì§ˆë¬¸ì´ ìžˆëŠ”ì§€ í™•ì¸
        text = str(x) if user_text is None else user_text
        return {"answer": text_mode(text, session_id), "label": None}


# ì¸ì‚¿ë§ í•¨ìˆ˜
def get_greeting():
    """ì•± ì²« ì‹¤í–‰ ì‹œ ë³´ì—¬ì¤„ ì¸ì‚¿ë§"""
    greeting = (
        "ì•ˆë…•í•˜ì„¸ìš”, íŒŒì£¼ ì¶œíŒë‹¨ì§€ ì±—ë´‡ íŒŒëž‘ì´ìž…ë‹ˆë‹¤.\n"
        "í…ìŠ¤íŠ¸ ìž…ë ¥ì´ë‚˜ ì´ë¯¸ì§€ ì—…ë¡œë“œë¥¼ í†µí•´ ì›í•˜ì‹œëŠ” ìž¥ì†Œì˜ ì •ë³´ë¥¼ ì•ˆë‚´ë°›ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
        "ë˜í•œ ì¶œíŒë‹¨ì§€ì—ì„œ ì˜ˆì •ëœ ë‹¤ì–‘í•œ í–‰ì‚¬ ì¼ì •ë„ í•¨ê»˜ í™•ì¸í•˜ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n\n"
        "ì‚¬ì§„ ì—…ë¡œë“œ ë°©ë²•:\n"
        "- ì‚¬ì§„ë§Œ ì—…ë¡œë“œ: ìž¥ì†Œ ì •ë³´ë¥¼ ìžë™ìœ¼ë¡œ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤.\n"
        "- ì‚¬ì§„ê³¼ í•¨ê»˜ ì§ˆë¬¸: 'ì´ ìž¥ì†Œê°€ ë­ì•¼?', 'ì´ê³³ì€ ì–´ë””ì¸ê°€ìš”?' ë“±ìœ¼ë¡œ ì§ˆë¬¸í•˜ì‹œë©´ ë” ìžì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n"
        "- ìŠ¤íƒ¬í”„ ì ë¦½: 'ìŠ¤íƒ¬í”„ ì ë¦½í•´ì¤˜', 'ì²´í¬ì¸' ë“±ê³¼ í•¨ê»˜ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì‹œë©´ ìŠ¤íƒ¬í”„ê°€ ì ë¦½ë©ë‹ˆë‹¤."
    )
    return greeting


if __name__ == "__main__":
    print(get_greeting(), "\n")
    session = "user_001"
    while True:
        sample = input("ìž…ë ¥ (quit ìž…ë ¥ ì‹œ ì¢…ë£Œ) >> ").strip()
        if sample.lower() == "quit":
            break
        result = infer_chat(sample, session)
        print(f"\n{result['answer']}\n")